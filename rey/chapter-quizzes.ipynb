{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1\n",
    "\n",
    "1. Can do deep learning without lots of math, lots of data, lots of expensive compute, or a PhD\n",
    "2. Deep learning is currently best in the world at NLP (incl document summarization, classification), image classification, image segmentation, speech recognition, text to speech, text to image, NER\n",
    "3. The first device that was based on the principle of the artificial neuron was [Mark I] perceptron [by Frank Rosenblatt]\n",
    "4. > A set of processing units, a state of activation, an output function for each unit, a pattern of connectivity among units, a propagation rule for propagating patterns of activities through the network of connectivities, an activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for that unit, a learning rule whereby patterns of connectivity are modified by experience, an environment within which the system must operate.\n",
    "5. The first theoretical misunderstanding that held back the field of neural nets was that ~complex operations~ simple but critical mathematical functions (such as XOR) were not able to be identified by just a one layer network/device. The other is that networks with 2 layers of neurons were originally (80s, 90s) too slow to be useful.\n",
    "6. GPU stands for Graphics Processing Unit\n",
    "7. 1+1 = 2\n",
    "8. Done\n",
    "9. Done\n",
    "10. It's hard to use a traditional program to recognize images in a photo because humans perform this task effortlessly so it is hard for them to enumerate all of the requisite features. Furthermore, it would be tedious to program all of these features using traditional code.\n",
    "11. Weight assignment has to do with iteratively tweaking values on the path toward reducing error rate. > In other words, evaluation and training of the model in order to obtain a set of parameter values that maximize model performance. As a noun, weight assignment refers to the current values of the model parameters. \n",
    "12. Samuel's weights are normally called parameters\n",
    "13. input,weights -> model -> result -> performance -> weights\n",
    "14. It's hard to understand why a deep learning model makes a particular predition because the internals of the neural net aren't explicitly visible. Also, there are many more parameters than can be analyzed at a glance. \n",
    "15. > Universal approximation theorem\n",
    "16. In order to train a model you need accurately labeled data. > You need an architecture for the given problem, labeled data, a loss function that will quantitatively measure the performance of the model, a way to update the parameters of the model in order to improve its performance.\n",
    "17. One of the issues with a predictive policing model is that biases that were originally present may be amplified. Police may use the model to determine where to focus activity, leading to more arrests in those areas, which would be fed back into the model, leading to an even more biased model. This would lead to a highly biased model with little predictive power. \n",
    "18. 224x224 was a requisite size for an old model. With modern models we can use any size as long as all of the input images get resized to the same dimensions. > You can increase the size and get better performance at the price of speed and memory consumption.\n",
    "19. Classification predicts a label/class/category from a discrete set. Regression is predicting a numeric quantity.\n",
    "20. Labeled data is segmented into 3 discrete parts - training set, validation set, and test set. Training set is used for training the model. Validation set is used for verifying the model. Test set is also used for verification of model correctness but is kept hidden from the engineer. \n",
    "> The validation set is the portion of the dataset that is not used for training the model, but for evaluating the model during training, in order to prevent overfitting. This ensures that the model performance is not due to “cheating” or memorization of the dataset, but rather because it learns the appropriate features to use for prediction. However, it is possible that we overfit the validation data as well. This is because the human modeler is also part of the training process, adjusting hyperparameters (see question 32 for definition) and training procedures according to the validation performance. Therefore, another unseen portion of the dataset, the test set, is used for final evaluation of the model. This splitting of the dataset is necessary to ensure that the model generalizes to unseen data.\n",
    "21. If you don't provide a validation set then fastai will segment data for you 0.8/0.2.\n",
    "22. You can't always use a random sample for the validation set due to the nature of the data. For timeseries data, a random selection would make it too easy for the model to fill in the gaps and overfit - better to select different time periods for validation, training, and test sets. For other kinds of data it could also vary, for example if labeling person behavior then data should be segmented by person such that no single person's data exists in more than one set (training, validation, test).\n",
    "> A good validation or test set should be representative of new data you will see in the future.\n",
    "23. Overfitting happens when the model is training poorly such that it \"memorizes\" specific features of the training set instead of learning general rules. This causes the model to perform poorly on new, unseen, data.\n",
    "> When the model fits too closely to a limited set of data but does not generalize well to new data.\n",
    "24. A metric is a human-readable and human-useful function of how well the model performs on the validation set. Loss is also a function of how well the model performs but it is used by optimization algorithm (SGD) to update model parameters.\n",
    "25. Pretrained models allow us to get results quicker and cheaper.\n",
    "26. When using a pretrained model, the ~head is~ later layers, which were useful for the task that the model was originally trained on, are removed and replaced by new layers with randomized weights. These new layers are called the \"head\".\n",
    "27. The early layers of a CNN find the smallest visual features such as straight lines or gradients. The latest layers find more complex features such as wheels, faces, text.\n",
    "28. Image models are useful for any data that can be transformed into meaningful images, including but not limited to sound (spetrograms), mouse movement \"maps\", timeseries data.\n",
    "29. Architecture is the template or structure of a model. It does not involve any data parameter values but defines the mathematical structure of how they will be used. Architecture + data => model\n",
    "30. Segmentation is a process for labeling each pixel in an image.\n",
    "31. > defines the range of (continuous) values, used for collaborative filtering (also, perhaps, other contexts)\n",
    "32. Hyperparameters are meta parameters that the engineer has direct control over - architecture, pretrained model selection, data massaging, how long to train for, learning rate. Parameters refer to the weights that are part of the model.\n",
    "33. Be mindful of biases included in data, they may be exacerbated when using the model. Be mindful of overfitting. \n",
    "> Make sure training, validation, and test sets are defined properly. \n",
    "\n",
    "## Further research\n",
    "1. A GPU is more useful for deep learning than a CPU because it has more memory, more memory bandwidth, and more parallel processing units. This enables GPUs to outperform CPUs when doing matrix multiplication, which causes them to be better for training NNs.\n",
    "2. *Think of ares where feedback loops might impact the use of machine learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "1. Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.\n",
    "> The model would poorly perform in production if the production input images were significantly different from the training data (out-of-domain data). For example, if the bears in production images were very far away, if the lighting conditions were different (nighttime), or if the environment was different (ex snow), prod images are too low-resolution, bear partially obstructed (esp facing away).\n",
    "\n",
    "2. Where do text models currently have a major deficiency?\n",
    "> Generating correct responses - for instance, to medically-correct answers.\n",
    "\n",
    "3. What are possible negative societal implications of text generation models?\n",
    "> Next level bots, worse than previously used troll farms, for spreading disinformation.\n",
    "\n",
    "4. In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?\n",
    "> Perform a gradual rollout of the system, scoped by time and/or location. Have a human oversee the system. Model could be integrated as an augmentation rather than a replacement, reducing risk but still improving efficiency of the workflow.\n",
    "\n",
    "5. What kind of tabular data is deep learning particularly good at?\n",
    "> Columns containing natural language (book titles, reviews, etc) and high-cardinality categorical columns (zip codes, authors, product IDs). \n",
    "\n",
    "6. What's a key downside of directly using a deep learning model for recommendation systems?\n",
    "> It will only say which products a particular user might like, rather than what recommendations would be helpful. This would not be great if user is already familiar with the products or if user has already purchased another version of the same product (different packaging).\n",
    "\n",
    "7. What are the steps of the Drivetrain Approach?\n",
    "> 1. Define your objective \n",
    "> 2. Determine what levers you can control - what actions you can take to meet that objective\n",
    "> 3. Determine what data you need to collect - what data you have or can acquire that can help\n",
    "> 4. Determine what model you can build, based on objective, levers, and available data. Now, build the model that you can use to determine the best actions to take to get the best results in terms of your objective\n",
    "> The goal is to produce actionable outcomes, not just data/predictions.\n",
    "\n",
    "8. How do the steps of the Drivetrain Approach map to a recommendation system?\n",
    "> objective - drive additional sales by surprising and delightning the customer with recomendations for items that they would not have purchased without the recommendation\n",
    "> lever - ranking of the recommendations\n",
    "> data - new data must be collected to generate recommendations that will cause new sales. This requires conducting many randomized experiments in order to collect data about a wide range of recommendations for a wide range of customers.\n",
    "> model - 2 models for purchase probabilities - condition on seeing or not seeing a recommendation. The difference between these two models is the utility function for a given recommendation to a customer.\n",
    "\n",
    "9. Create an image recognition model using data you curate, and deploy it on the web.\n",
    "\n",
    "10. What is DataLoaders?\n",
    "> A class that passes data to the fastai model, it stores the required Dataloaders objects for train and validation sets.\n",
    "\n",
    "11. What four things do we need to tell fastai to create DataLoaders?\n",
    "> What kind of data it is, how to get the data, how to label it, how much data to reserve for validation set\n",
    "\n",
    "12. What does the splitter parameter to DataBlock do?\n",
    "> Specifies percentage of data to reserve for validation set. It also includes a seed so that the data split remains constant between runs.\n",
    "\n",
    "13. How do we ensure a random split always gives the same validation set?\n",
    "> Via the RandomSplitter seed\n",
    "\n",
    "14. What letters are often used to signify the independent and dependent variables?\n",
    "> x - independent\n",
    "> y - dependent\n",
    "\n",
    "15. What's the difference between the crop, pad, and squish resize approaches? When might you choose one over the others?\n",
    "> Crop - cuts part of the image - may crop out essential information\n",
    "> Pad - pads image with white or black pixels to make a square - causes empty space which causes wasted computation, results in lower effective resolution for the useful part of the image.\n",
    "> Squish - changes aspect ratio by squishing or stretching - causes an unrealistic shape, causes model to learn that things look different from how they actually are.\n",
    "> Which method to use depents on the underlying problem and dataset.\n",
    "> In practice, it doesn't really matter? Often best to use RandomResizedCrop for photo-realistic images.\n",
    "\n",
    "16. What is data augmentation? Why is it needed?\n",
    "> Modifying the training set data to make it more varied, such as with random risize crop or aug transforms. It makes the images appear different but retains their meaning. It trains the model on more \"realistic\" data as in production, the incoming images will be less than perfect. It helps the model to generalize!!\n",
    "\n",
    "17. What is the difference between item_tfms and batch_tfms?\n",
    "> item_tfms runs function runs on each item individually (runs on CPU), can be used to resize. batch_tfms runs on multiple items simultaneously (runs on GPU), can be used for aug_transforms.\n",
    "\n",
    "18. What is a confusion matrix?\n",
    "> A matrix representation of predictions made vs the correct labels. Top-left - bottom-right diagonal shows the number of correct predictions. Other squares show the number of incorrect predictions.\n",
    "\n",
    "19. What does export save?\n",
    "> The architecture, parameters, and DataLoaders definition\n",
    "\n",
    "20. What is it called when we use a model for getting predictions, instead of training?\n",
    "> Inference\n",
    "\n",
    "21. What are IPython widgets?\n",
    "> A library for generating front-end widgets with Python code\n",
    "\n",
    "22. When might you want to use CPU for deployment? When might GPU be better?\n",
    "> CPUs are best when analyzing single pieces of data at a time. Also, CPU hosting is more competitive and available so it is generally more cost-effective. Once the product is proven to be successful then can think about moving the deployment to a GPU, even still the performance increase needs to be measured against cost.\n",
    "> GPUs are best for doing identical work in prallel.\n",
    "\n",
    "23. What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC?\n",
    "> Latency from network (although may still overall be faster as server likely has more compute), required connection to Internet, privacy concerns.\n",
    "> Positives of server deployment: easier to iterate and roll out new versions of a model.\n",
    "\n",
    "24. What are three examples of problems that could occur when rolling out a bear warning system in practice?\n",
    "> Poor camera resolution may provide inadequate images, night time images may not have been used for training, model might return predictions too slowly to be useful.\n",
    "\n",
    "25. What is \"out-of-domain data\"?\n",
    "> Data that is fundamentally different from model's training data.\n",
    "\n",
    "26. What is \"domain shift\"?\n",
    "> When the type of data changes gradually over time. \n",
    "> For example, over time customers change and original training data is no longer representative of current data; model is now applied to out-of-domain data.\n",
    "\n",
    "27. What are the three steps in the deployment process?\n",
    "> Manual process - run model in parallel with human, humans checks all predictions, model does not drive any actions\n",
    "> Limited scope deployment - careful human supervision, time or geography limited\n",
    "> Gradual expansion - score is gradually increased, good reporting systems are implemented to check for significant changes to actions compared with the manual process (model should generally perform similarly to humans, unless it is already anticipated to be better)\n",
    "\n",
    "## Further Research\n",
    "1. Consider how the Drivetrain Approach maps to a project or problem you're interested in.\n",
    "2. When might it be best to avoid certain types of data augmentation?\n",
    "> May be good to avoid aug_transforms when dealing with images that are not \"natural photos\"\n",
    "3. For a project you're interested in applying deep learning to, consider the thought experiment \"What would happen if it went really, really well?\"\n",
    "4. Start a blog, and write your first blog post. For instance, write about what you think deep learning might be useful for in a domain you're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
