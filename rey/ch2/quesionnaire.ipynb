{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "1. Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.\n",
    "> The model would poorly perform in production if the production input images were significantly different from the training data (out-of-domain data). For example, if the bears in production images were very far away, if the lighting conditions were different (nighttime), or if the environment was different (ex snow), prod images are too low-resolution, bear partially obstructed (esp facing away).\n",
    "\n",
    "2. Where do text models currently have a major deficiency?\n",
    "> Generating correct responses - for instance, to medically-correct answers.\n",
    "\n",
    "3. What are possible negative societal implications of text generation models?\n",
    "> Next level bots, worse than previously used troll farms, for spreading disinformation.\n",
    "\n",
    "4. In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?\n",
    "> Perform a gradual rollout of the system, scoped by time and/or location. Have a human oversee the system. Model could be integrated as an augmentation rather than a replacement, reducing risk but still improving efficiency of the workflow.\n",
    "\n",
    "5. What kind of tabular data is deep learning particularly good at?\n",
    "> Columns containing natural language (book titles, reviews, etc) and high-cardinality categorical columns (zip codes, authors, product IDs).\n",
    "\n",
    "6. What's a key downside of directly using a deep learning model for recommendation systems?\n",
    "> It will only say which products a particular user might like, rather than what recommendations would be helpful. This would not be great if user is already familiar with the products or if user has already purchased another version of the same product (different packaging).\n",
    "\n",
    "7. What are the steps of the Drivetrain Approach?\n",
    "> 1. Define your objective\n",
    "> 2. Determine what levers you can control - what actions you can take to meet that objective\n",
    "> 3. Determine what data you need to collect - what data you have or can acquire that can help\n",
    "> 4. Determine what model you can build, based on objective, levers, and available data. Now, build the model that you can use to determine the best actions to take to get the best results in terms of your objective\n",
    "> The goal is to produce actionable outcomes, not just data/predictions.\n",
    "\n",
    "8. How do the steps of the Drivetrain Approach map to a recommendation system?\n",
    "> objective - drive additional sales by surprising and delightning the customer with recomendations for items that they would not have purchased without the recommendation\n",
    "> lever - ranking of the recommendations\n",
    "> data - new data must be collected to generate recommendations that will cause new sales. This requires conducting many randomized experiments in order to collect data about a wide range of recommendations for a wide range of customers.\n",
    "> model - 2 models for purchase probabilities - condition on seeing or not seeing a recommendation. The difference between these two models is the utility function for a given recommendation to a customer.\n",
    "\n",
    "9. Create an image recognition model using data you curate, and deploy it on the web.\n",
    "\n",
    "10. What is DataLoaders?\n",
    "> A class that passes data to the fastai model, it stores the required Dataloaders objects for train and validation sets.\n",
    "\n",
    "11. What four things do we need to tell fastai to create DataLoaders?\n",
    "> What kind of data it is, how to get the data, how to label it, how much data to reserve for validation set\n",
    "\n",
    "12. What does the splitter parameter to DataBlock do?\n",
    "> Specifies percentage of data to reserve for validation set. It also includes a seed so that the data split remains constant between runs.\n",
    "\n",
    "13. How do we ensure a random split always gives the same validation set?\n",
    "> Via the RandomSplitter seed\n",
    "\n",
    "14. What letters are often used to signify the independent and dependent variables?\n",
    "> x - independent\n",
    "> y - dependent\n",
    "\n",
    "15. What's the difference between the crop, pad, and squish resize approaches? When might you choose one over the others?\n",
    "> Crop - cuts part of the image - may crop out essential information\n",
    "> Pad - pads image with white or black pixels to make a square - causes empty space which causes wasted computation, results in lower effective resolution for the useful part of the image.\n",
    "> Squish - changes aspect ratio by squishing or stretching - causes an unrealistic shape, causes model to learn that things look different from how they actually are.\n",
    "> Which method to use depents on the underlying problem and dataset.\n",
    "> In practice, it doesn't really matter? Often best to use RandomResizedCrop for photo-realistic images.\n",
    "\n",
    "16. What is data augmentation? Why is it needed?\n",
    "> Modifying the training set data to make it more varied, such as with random risize crop or aug transforms. It makes the images appear different but retains their meaning. It trains the model on more \"realistic\" data as in production, the incoming images will be less than perfect. It helps the model to generalize!!\n",
    "\n",
    "17. What is the difference between item_tfms and batch_tfms?\n",
    "> item_tfms runs function runs on each item individually (runs on CPU), can be used to resize. batch_tfms runs on multiple items simultaneously (runs on GPU), can be used for aug_transforms.\n",
    "\n",
    "18. What is a confusion matrix?\n",
    "> A matrix representation of predictions made vs the correct labels. Top-left - bottom-right diagonal shows the number of correct predictions. Other squares show the number of incorrect predictions.\n",
    "\n",
    "19. What does export save?\n",
    "> The architecture, parameters, and DataLoaders definition\n",
    "\n",
    "20. What is it called when we use a model for getting predictions, instead of training?\n",
    "> Inference\n",
    "\n",
    "21. What are IPython widgets?\n",
    "> A library for generating front-end widgets with Python code\n",
    "\n",
    "22. When might you want to use CPU for deployment? When might GPU be better?\n",
    "> CPUs are best when analyzing single pieces of data at a time. Also, CPU hosting is more competitive and available so it is generally more cost-effective. Once the product is proven to be successful then can think about moving the deployment to a GPU, even still the performance increase needs to be measured against cost.\n",
    "> GPUs are best for doing identical work in prallel.\n",
    "\n",
    "23. What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC?\n",
    "> Latency from network (although may still overall be faster as server likely has more compute), required connection to Internet, privacy concerns.\n",
    "> Positives of server deployment: easier to iterate and roll out new versions of a model.\n",
    "\n",
    "24. What are three examples of problems that could occur when rolling out a bear warning system in practice?\n",
    "> Poor camera resolution may provide inadequate images, night time images may not have been used for training, model might return predictions too slowly to be useful.\n",
    "\n",
    "25. What is \"out-of-domain data\"?\n",
    "> Data that is fundamentally different from model's training data.\n",
    "\n",
    "26. What is \"domain shift\"?\n",
    "> When the type of data changes gradually over time.\n",
    "> For example, over time customers change and original training data is no longer representative of current data; model is now applied to out-of-domain data.\n",
    "\n",
    "27. What are the three steps in the deployment process?\n",
    "> Manual process - run model in parallel with human, humans checks all predictions, model does not drive any actions\n",
    "> Limited scope deployment - careful human supervision, time or geography limited\n",
    "> Gradual expansion - score is gradually increased, good reporting systems are implemented to check for significant changes to actions compared with the manual process (model should generally perform similarly to humans, unless it is already anticipated to be better)\n",
    "\n",
    "## Further Research\n",
    "1. Consider how the Drivetrain Approach maps to a project or problem you're interested in.\n",
    "2. When might it be best to avoid certain types of data augmentation?\n",
    "> May be good to avoid aug_transforms when dealing with images that are not \"natural photos\"\n",
    "3. For a project you're interested in applying deep learning to, consider the thought experiment \"What would happen if it went really, really well?\"\n",
    "4. Start a blog, and write your first blog post. For instance, write about what you think deep learning might be useful for in a domain you're interested in.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
